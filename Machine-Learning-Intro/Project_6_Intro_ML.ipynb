{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 7 Project: Intro to Machine Learning\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Open and Confirm Quality of Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('users_behavior.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**is_ultra: 1 = Ultra, 0 = Smart**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calls       0\n",
       "minutes     0\n",
       "messages    0\n",
       "mb_used     0\n",
       "is_ultra    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick look at the data to confirm it is clean and in good shape, including dtypes, null values, and an understanding of each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Split Data: Train, Validate, Test\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I plan to split the data 60-20-20 (train-validate-test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(df, test_size=0.4, random_state=1)\n",
    "valid, test = train_test_split(val, test_size=0.5, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1928, 4)\n",
      "(1928,)\n",
      "(643, 4)\n",
      "(643,)\n",
      "(643, 4)\n",
      "(643,)\n"
     ]
    }
   ],
   "source": [
    "x_train = train.drop('is_ultra', axis=1)\n",
    "y_train = train['is_ultra']\n",
    "\n",
    "x_val = valid.drop('is_ultra', axis=1)\n",
    "y_val = valid['is_ultra']\n",
    "\n",
    "x_test = test.drop('is_ultra', axis=1)\n",
    "y_test = test['is_ultra']\n",
    "\n",
    "# confirming size of each set\n",
    "lis = [x_train, y_train, x_val, y_val, x_test, y_test]\n",
    "for x in lis:\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Investigate Different Models and Hyperparameters\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth = 6 -- accuracy = 0.7729393468118196\n",
      "depth = 7 -- accuracy = 0.7838258164852255\n",
      "depth = 8 -- accuracy = 0.776049766718507\n"
     ]
    }
   ],
   "source": [
    "# started with range(1,11,2), then narrowed down to range(6,9)\n",
    "\n",
    "for d in range(6,9):\n",
    "    dtc_model = DecisionTreeClassifier(max_depth=d, random_state=123)\n",
    "    dtc_model.fit(x_train, y_train)\n",
    "    dtc_pred = dtc_model.predict(x_val)\n",
    "    dtc_acc = accuracy_score(y_val, dtc_pred)\n",
    "    print('depth =', d, '-- accuracy =', dtc_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best Decision Tree Classifier:**\n",
    "- max_depth = 7\n",
    "- accuracy = 0.783"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 15 -- accuracy = 0.7791601866251944\n",
      "n_estimators = 16 -- accuracy = 0.7807153965785381\n",
      "n_estimators = 17 -- accuracy = 0.7884914463452566\n",
      "n_estimators = 18 -- accuracy = 0.7822706065318819\n",
      "n_estimators = 19 -- accuracy = 0.7869362363919129\n"
     ]
    }
   ],
   "source": [
    "# started with range(1,22,4), then narrowed down to range(15,20)\n",
    "\n",
    "for n in range(15,20):\n",
    "    rfc_model = RandomForestClassifier(random_state=12345, n_estimators=n)\n",
    "    rfc_model.fit(x_train, y_train)\n",
    "    rfc_pred = rfc_model.predict(x_val)\n",
    "    rfc_acc = accuracy_score(y_val, rfc_pred)\n",
    "    print('n_estimators =', n, '-- accuracy =', rfc_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best Random Forest Classifier:**\n",
    "- n_estimators = 17\n",
    "- accuracy = 0.788"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy = 0.6951788491446346\n"
     ]
    }
   ],
   "source": [
    "# No hyperparamter tuning done here\n",
    "\n",
    "logreg_model = LogisticRegression(random_state=12345, solver='liblinear', max_iter=100)\n",
    "logreg_model.fit(x_train, y_train)\n",
    "logreg_pred = logreg_model.predict(x_val)\n",
    "logreg_acc = accuracy_score(y_val, logreg_pred)\n",
    "print('Model Accuracy =', logreg_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The models compared were decision tree, random forest, and logistic regression because this is a classification problem\n",
    "- For each model I, attempted to tune a specific parameter and narrowed the range towards the most accurate:\n",
    "    - Decision Tree used max_depth\n",
    "    - Random Forest used n_estimators\n",
    "    - Logistic Regression used max_iter (I came across this parameter and tried many numbers, but it never affected the accuracy)\n",
    "    \n",
    "    \n",
    "- The most accurate model ended up bein the **Random Forest Classifier with n_estimators=17 and Accuracy=0.788**\n",
    "- The Decision Tree was similar but a little less accurate at 0.783\n",
    "- The Logistic Regression was much lower than the others at 0.695"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Check Model Quality with Test Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2571, 4)\n",
      "(2571,)\n"
     ]
    }
   ],
   "source": [
    "# Adding the train and validation data together to train the model on more data before seeing the test set\n",
    "\n",
    "xx = [x_train, x_val]\n",
    "x_full = pd.concat(xx)\n",
    "\n",
    "yy = [y_train, y_val]\n",
    "y_full = pd.concat(yy)\n",
    "\n",
    "print(x_full.shape)\n",
    "print(y_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Accuracy: 79.00%\n"
     ]
    }
   ],
   "source": [
    "# Final Model based on validation\n",
    "\n",
    "final_model = RandomForestClassifier(random_state=12345, n_estimators=17)\n",
    "final_model.fit(x_full, y_full)\n",
    "\n",
    "final_pred = final_model.predict(x_test)\n",
    "\n",
    "final_acc = accuracy_score(y_test, final_pred)\n",
    "\n",
    "print('Final Model Accuracy: {:.2f}%'.format(final_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My final model ended up with **79% accuracy** on the test data. This means that the model correctly predicted 508 out of 643 datapoints correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Sanity Check\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I wanted the model to be at least better than 50% accuracy since this is a binary classification problem where guessing at random would get around 50% correct.\n",
    "- The project goal was to get better than 75% accuracy\n",
    "- With my model scoring 79%, it successfully surpassed both thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Conclusion\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, I was able to go through three different simple classification models and determine which one performed the best based on accuracy on the validation data. Each model tested was tuned with a single hyperparameter which was narrowed down until the best accuracy was found. Upon finding the best one (Random Forest) I created the final model with the best tuned parameters, trained it on both the training and validation set, and finally tested the model with the test data to end up with a 79% accuracy, surpassing bothe the sanity check accuracy (50%) and the project accuracy threshold (75%). I am happy with my final model accuracy, but I am sure there are other parameters and model types I do not yet know of with some combination that performs better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
